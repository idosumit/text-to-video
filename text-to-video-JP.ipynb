{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the required libraries\n",
    "# !pip install python-docx\n",
    "# !pip install pytesseract\n",
    "# !pip install gtts\n",
    "# !pip install opencv-python-headless\n",
    "# !pip install opencv-python\n",
    "# !pip install moviepy\n",
    "# !pip install googletrans==4.0.0-rc1\n",
    "# !pip install docx2python\n",
    "# !pip install tinytag\n",
    "# !pip install Pillow\n",
    "# !pip install pydub\n",
    "# !pip install docx2txt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from docx import Document\n",
    "from googletrans import Translator\n",
    "import moviepy.editor as mp\n",
    "from gtts import gTTS\n",
    "from moviepy.editor import *\n",
    "from moviepy.editor import concatenate_videoclips\n",
    "from moviepy.video.fx import resize\n",
    "from moviepy.video.io.ImageSequenceClip import ImageSequenceClip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reading the Word document, extract paragraphs, and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from PIL import Image\n",
    "import uuid\n",
    "\n",
    "def read_word_document(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]\n",
    "\n",
    "    images = []\n",
    "    for idx, shape in enumerate(doc.inline_shapes):\n",
    "        img_id = str(uuid.uuid4())\n",
    "        if shape.type == docx.enum.shape.WD_INLINE_SHAPE.PICTURE:\n",
    "            blip = shape._inline.graphic.graphicData.pic.blipFill.blip\n",
    "            if blip.embed is not None:\n",
    "                rId = blip.embed\n",
    "            else:\n",
    "                rId = blip.link\n",
    "            document_part = doc.part\n",
    "            image_part = document_part.related_parts[rId]\n",
    "            img_data = image_part.blob\n",
    "            extension = os.path.splitext(image_part.partname)[1]\n",
    "            image_path = f'image_{img_id}{extension}'\n",
    "            with open(image_path, 'wb') as f:\n",
    "                f.write(img_data)\n",
    "            img = Image.open(image_path)\n",
    "            img.save(image_path)\n",
    "            images.append(image_path)\n",
    "\n",
    "    return paragraphs, images\n",
    "\n",
    "file_path = '/Users/psumit/Documents/Career/Codespace/Projects/text-to-video/text-to-video-JP1/test4page-JP.docx'\n",
    "paragraphs, images = read_word_document(file_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generating audio files for each paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "def generate_audio_files(paragraphs, language_code='ja'):\n",
    "    audio_files = []\n",
    "    for idx, paragraph in enumerate(paragraphs):\n",
    "        tts = gTTS(text=paragraph, lang=language_code)\n",
    "        audio_file = f\"audio_{idx}.mp3\"\n",
    "        tts.save(audio_file)\n",
    "        audio_files.append(audio_file)\n",
    "    return audio_files\n",
    "\n",
    "language_code = \"ja\"\n",
    "audio_files = generate_audio_files(paragraphs, language_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Creating the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "def wrap_text(text, max_width=50):\n",
    "    lines = textwrap.wrap(text, width=max_width)\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def resize_image_maintain_aspect_ratio(image, width, height):\n",
    "    image.thumbnail((width, height), Image.ANTIALIAS)\n",
    "    return image\n",
    "\n",
    "def create_video(paragraphs, images, audio_files, output_path='output_video.mp4'):\n",
    "    clips = []\n",
    "\n",
    "    intro_text = wrap_text(paragraphs[0])\n",
    "    outro_text = wrap_text(paragraphs[-1])\n",
    "\n",
    "    intro_clip = TextClip(intro_text, fontsize=24, color='white', size=(1280, 720), bg_color='black', print_cmd=False).set_duration(5)\n",
    "    clips.append(intro_clip.set_audio(mp.AudioFileClip(audio_files[0])))\n",
    "\n",
    "    for i in range(1, len(paragraphs) - 1):\n",
    "        image = Image.open(images[i - 1])\n",
    "        image = resize_image_maintain_aspect_ratio(image, 1280, 720)\n",
    "        image = image.convert('RGB')\n",
    "        image.save(f\"temp_{i}.jpg\")\n",
    "        audio_duration = mp.AudioFileClip(audio_files[i]).duration\n",
    "        img_clip = ImageClip(f\"temp_{i}.jpg\", duration=audio_duration)\n",
    "        img_clip = img_clip.set_audio(mp.AudioFileClip(audio_files[i]))\n",
    "        clips.append(img_clip)\n",
    "\n",
    "    outro_clip = TextClip(outro_text, fontsize=24, color='white', size=(1280, 720), bg_color='black', print_cmd=False).set_duration(5)\n",
    "    clips.append(outro_clip.set_audio(mp.AudioFileClip(audio_files[-1])))\n",
    "\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "    final_clip.write_videofile(output_path, codec='libx264', fps=24)\n",
    "\n",
    "create_video(paragraphs, images, audio_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 problems?\n",
    "\n",
    "- The images are still very blurry, almost as if a signal has gone off in a TV. I need to resolve this.\n",
    "\n",
    "- The audios for every paragraph. If I have to describe it clearly, the video plays like this:\n",
    "    \n",
    "    a. The video starts playing with the black screen with the audio transcription.\n",
    "    \n",
    "    b. Although the introductory paragraph's audio transcript has not yet finished, paragraph 1's audio transcription begins.\n",
    "    \n",
    "    Big problem. Paragraph 1's audio and image should not be heard and visible until the introductory paragraph is done.\n",
    "\n",
    "The code fails to consider when the audio transcription ends for a paragraph so that it can\n",
    "\n",
    "go to the transcription for the following paragraph.\n",
    "\n",
    "So, I need to find a way to consider the length of each paragraph so that the audio transcriptions\n",
    "\n",
    "do not end up cluttering each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-to-video-GPT4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
